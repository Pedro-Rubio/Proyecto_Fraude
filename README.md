# Detecci√≥n de Fraude en Transacciones ‚Äî MVP de Ciencia de Datos

> **Objetivo:** construir un sistema reproducible de detecci√≥n de fraude que va desde la exploraci√≥n y limpieza de datos, pasando por entrenamiento y validaci√≥n sin fuga de informaci√≥n, hasta el **despliegue operativo** en una app de **Streamlit** con una pol√≠tica de **triage** (ALTO_RIESGO / REVISAR / OK) y tableros anal√≠ticos en **Tableau/Power BI**.

---

## üß≠ Tabla de contenidos

- [Contexto del negocio](#contexto-del-negocio)
- [Arquitectura general](#arquitectura-general)
- [Estructura del repositorio](#estructura-del-repositorio)
- [Entorno](#entorno)
- [Datos](#datos)
- [Pipeline de features y entrenamiento](#pipeline-de-features-y-entrenamiento)
- [Prevenci√≥n de fuga de informaci√≥n](#prevenci√≥n-de-fuga-de-informaci√≥n)
- [M√©tricas y resultados](#m√©tricas-y-resultados)
- [Pol√≠tica de triage (MVP operativo)](#pol√≠tica-de-triage-mvp-operativo)
- [App Streamlit (scoring por lote)](#app-streamlit-scoring-por-lote)
- [Dashboards BI (Tableau/Power BI)](#dashboards-bi-tableaupower-bi)
- [Pruebas unitarias](#pruebas-unitarias)
- [C√≥mo replicar](#c√≥mo-replicar)
- [Hoja de ruta / Mejoras futuras](#hoja-de-ruta--mejoras-futuras)
- [Responsabilidad y limitaciones](#responsabilidad-y-limitaciones)
- [Autor](#autor)

---

## üíº Contexto del negocio

Los fraudes con tarjeta impactan directamente en p√©rdidas financieras y experiencia del cliente. Este MVP prioriza:

1. **Detectar casos de alto riesgo** con **precisi√≥n m√≠nima garantizada** (para evitar bloqueos injustificados).
2. **Maximizar recall** bajo capacidad humana limitada mediante una bandeja **REVISAR** ordenada por **p√©rdida esperada** (*expected_loss = prob*fraude √ó amount*).
3. Entregar **insights ejecutables** (ciudades/giros de mayor incidencia, bandas de monto, horarios) para prevenci√≥n y monitoreo.

---

## üèó Arquitectura general

- **Ingesta/Limpieza:** `cards_data.csv`, `transactions_data.csv`, `users_data.csv` ‚Üí `dataset_final_limpio.csv`.
- **Features & Split:** ingenier√≠a de variables con **GroupKFold** por cliente y corte temporal (evita fuga).
- **Modelos:** *Logistic Regression* + *RandomForest* (baselines) y opci√≥n *LightGBM* (si est√° disponible).
- **Selecci√≥n & Umbral:** m√©trica objetivo **PR AUC** y ajuste de umbral por **coste de errores** o **precisi√≥n m√≠nima**.
- **Despliegue:** app **Streamlit** para scoring por lote (CSV), con **triage** y descarga de resultados.
- **BI:** dashboard en **Tableau/Power BI/Looker Studio** con KPIs, serie temporal, top ciudades/giros y mapa.

---

## üìÅ Estructura del repositorio

```text
proyecto_fraude/
‚îú‚îÄ app.py                                    # App Streamlit (MVP operativo)
‚îú‚îÄ requirements.txt                          # Dependencias (pinneadas a Py 3.11 / sklearn 1.4)
‚îú‚îÄ runtime.txt                               # python-3.11 (Streamlit Cloud)
‚îú‚îÄ sample_data/
‚îÇ  ‚îî‚îÄ sample_10_transactions.csv             # CSV de prueba para la app
‚îú‚îÄ artifacts_noleak_v1/                      # Artefactos para producci√≥n
‚îÇ  ‚îú‚îÄ best_so_far.pkl                        # Pipeline (prep + modelo)
‚îÇ  ‚îú‚îÄ triage_thresholds.json                 # Umbrales/parametr√≠a por defecto del MVP
‚îú‚îÄ notebooks/
‚îÇ  ‚îú‚îÄ Proyecto_Data_Fraude_Depurado.ipynb    # Exploraci√≥n + limpieza + carga + Desarrollo de ML
‚îú‚îÄ Data Visualizacion/
‚îÇ  ‚îú‚îÄ Proyecto_Power_ BI                     # Visualizaciones desarrolladas en Microsoft Power BI
‚îÇ  ‚îú‚îÄ Proyecto_Looker_Studio                 # Visualizaciones desarrolladas en Looker Studio
‚îî‚îÄ README.md
```

---

## üß∞ Entorno

Recomendado: **Python 3.11** (coherente con el pickle de sklearn).

`runtime.txt`
```
python-3.11
```

`requirements.txt`
```
streamlit==1.36.0
pandas==2.2.2
numpy==1.26.4
scikit-learn==1.4.2
joblib==1.4.2
matplotlib==3.8.4
```

> ‚ö†Ô∏è Usar otra versi√≥n de `scikit-learn` puede romper la carga del `best_so_far.pkl`.

---

## üóÇ Datos

- **transactions_data.csv**: transacciones (amount, mcc, merchant_city/state, zip, hour/day, use_chip, etc.)
- **cards_data.csv**: atributos de tarjeta (card_brand/tipo, fechas de emisi√≥n/expiraci√≥n, chip, dark web flag, etc.)
- **users_data.csv**: atributos del cliente (edad, g√©nero, ingresos aproximados o per c√°pita del zip, etc.)

üßΩ **Limpieza (resumen):**

- Tipos coherentes (`date` a datetime, `amount` a float, ids a int/string).
- Tratamiento de nulos (imputaci√≥n por mediana/moda seg√∫n tipo).
- Eliminaci√≥n de columnas con >50% nulos y alta cardinalidad textual sin valor.
- Features de **tiempo** (a√±o, mes, hora, d√≠a semana), **riesgo de monto**, **frecuencias por cliente**, etc.

Salida: **`dataset_final_limpio.csv`**.

---

## üîß Pipeline de features y entrenamiento

- **Preprocesamiento** v√≠a `ColumnTransformer`:
  - Num√©ricas: `SimpleImputer(median)` + `StandardScaler`.
  - Categ√≥ricas: `SimpleImputer(most_frequent)` + `OneHotEncoder(handle_unknown='ignore')`.
- **Split sin fuga**:
  - **GroupKFold** por `client_id` (evita que el mismo cliente est√© en train y test).
  - **Corte temporal** (train: fechas anteriores, test: posteriores) para simular producci√≥n.
- **Baselines**:
  - `LogisticRegression(class_weight='balanced')`
  - `RandomForestClassifier(class_weight='balanced')`
- **Selecci√≥n** por **PR AUC** (promedio en CV).
- **Umbrales**:
  - Por coste (`C_FP`, `C_FN`) **o** por precisi√≥n m√≠nima (ej. 0.80) maximizando recall.

Artefactos clave: **`artifacts_noleak_v1/best_so_far.pkl`** y **`triage_thresholds.json`**.

---

## üß™ Prevenci√≥n de fuga de informaci√≥n

- No se usan variables derivadas de la etiqueta.
- Split por **cliente** y **tiempo**.
- Imputaci√≥n/escala/OHE ajustados **solo** en train (v√≠a pipeline).
- Evaluaci√≥n en **holdout** verdaderamente out-of-sample.

---

## üìä M√©tricas y resultados

- **PR AUC** (objetivo) y **ROC AUC**.
- Reporte de clasificaci√≥n a umbral √≥ptimo (coste o precisi√≥n m√≠nima).
- Ejemplo reciente (dataset de demostraci√≥n muy desbalanceado):
  - PR AUC (holdout) ‚âà **0.99**
  - ROC AUC (holdout) ‚âà **1.00**
  - Umbral seleccionado para **Precision ‚â• 0.60** con **Recall ‚âà 1.00** en **ALTO_RIESGO**.

> ‚ö†Ô∏è En datasets sint√©ticos o con reglas ‚Äúf√°ciles‚Äù, las m√©tricas pueden ser extremadamente altas. En producci√≥n, se espera descenso y se ajusta umbral/capacidad de revisi√≥n.

---

## üß≠ Pol√≠tica de triage (MVP operativo)

1. **ALTO_RIESGO:** probabilidad ‚â• `thr_high` (por defecto 0.99 o se re-estima con `is_fraud` del CSV).
2. **REVISAR:** Top-N casos (configurable) por **p√©rdida esperada** `prob * amount`.
3. **OK:** resto.

Archivos de configuraci√≥n (editables):
- `artifacts_noleak_v1/triage_thresholds.json`:
  ```json
  {
    "thr_high": 0.99,
    "min_precision_high": 0.80,
    "review_capacity": 200
  }
  ```

---

## üåê App Streamlit (scoring por lote)

**Funcionalidad:**
- Subir CSV con columnas esperadas por el pipeline.
- Scoring por lote y asignaci√≥n de triage.
- Descarga del CSV con `score`, `expected_loss` y `triage`.
- Si el CSV trae `is_fraud`, la app muestra m√©tricas (PR AUC, ROC AUC, reporte y matriz).
- Panel de info del modelo: columnas num/cat y (si aplica) importancias.

**Ejecuci√≥n local:**
```bash
# 1) Crear venv (opcional)
python -m venv .venv && source .venv/bin/activate  # (Win: .venv\Scripts\activate)

# 2) Instalar deps
pip install -r requirements.txt

# 3) Ejecutar la app
streamlit run app.py
```

**Despliegue en Streamlit Cloud:**
- Asegura `runtime.txt` con **python-3.11**.
- `requirements.txt` con versiones pinneadas.
- Sube `artifacts_noleak_v1/best_so_far.pkl` y `triage_thresholds.json` al repo.

---

## üìà Dashboards BI (Tableau/Power BI/ Looker Studio)

**Tablero Resumen Ejecutivo:**
- KPIs: **Total Transacciones**, **Total Fraudes**, **Tasa de Fraude**, **Monto Total**.
- Serie temporal por **mes** (fraudes y/o transacciones).
- **Top 10** ciudades/giros por fraudes (y monto defraudado).
- **Mapa** (burbuja por ciudad o coordenadas).
- Filtros globales: **rango de fecha**, **estado/pa√≠s**, **tipo de tarjeta**.

> En Tableau/Power BI, `amount` ‚Üí num√©rico; crear **banda de monto**; derivar **Fecha Mes** con `DATETRUNC('month', date)` (Tableau) o `EOMONTH` (DAX).

---

## ‚úÖ Pruebas unitarias

`tests/test_model.py`
- **Forma de salida:** para input `n√óp` devuelve `n` scores/clases.
- **Rango de predict_proba:** `[0,1]`.
- **Dominio de etiquetas:** `{0,1}`.

Ejemplo:
```python
import joblib, numpy as np

def test_proba_output_range():
    pipe = joblib.load("artifacts_noleak_v1/best_so_far.pkl")
    X = np.random.rand(5, 27)  # adapta p a tus columnas num√©ricas
    y_prob = pipe.predict_proba(X)[:, 1]
    assert np.all((0 <= y_prob) & (y_prob <= 1))
```
Ejecuci√≥n:
```bash
pytest -q
```

---

## üîÅ C√≥mo replicar

1. **Preparar datos**
   - Coloca tus CSV en `data/` o ajusta paths en los notebooks.
   - Ejecuta `notebooks/01_eda_y_limpieza.ipynb` ‚áí `dataset_final_limpio.csv`.

2. **Features + entrenamiento**
   - Ejecuta `notebooks/03_training_noleak.ipynb` para entrenar con **GroupKFold + corte temporal**.
   - El notebook guarda `best_so_far.pkl` y m√©tricas en `artifacts_noleak_v1/`.

3. **App local**
   - `pip install -r requirements.txt`
   - `streamlit run app.py`

4. **App nube**
   - Sube repo a GitHub (incluyendo `artifacts_noleak_v1/`).
   - Deploy en Streamlit Cloud.

---

## üó∫ Hoja de ruta / Mejoras futuras

- **M√°s modelos:** calibraci√≥n, LightGBM/XGBoost con *early stopping*.
- **Detecci√≥n secuencial:** features basadas en ventanas por cliente/merchant.
- **Monitorizaci√≥n en producci√≥n:** drift, performance y umbrales adaptativos.
- **Explainability:** SHAP/Permutaci√≥n para explicar decisiones.
- **Integraci√≥n tiempo real:** API para scoring online + colas (Kafka/Redis).
- **Riesgo/Gobernanza:** auditor√≠a, bit√°coras y *model cards* ampliadas.

---

## ‚öñÔ∏è Responsabilidad y limitaciones

- Datos **sint√©ticos o anonimizados** para portafolio.  
- M√©tricas altas pueden deberse a distribuciones favorables; en producci√≥n se espera ruido, *concept drift* y costo de etiquetado.  
- Evitar sesgos: revisar disparidad por segmentos (g√©nero/zipcode/edad) antes de liberar decisiones automatizadas.

---

## üë§ Autor

**Ezequiel Gonzalez** ‚Äî Data Science & Analytics 
- *ezequiel.gonzalez08a@gmail.com*
**Pedro Rubio**  

- App Streamlit *https://proyectofraude-hyd2ycaphdnqqbeo87scer.streamlit.app/*, BI con Tableau/Power BI.
- Notebook/Google Colab: *https://colab.research.google.com/drive/1_Ed65bITdC714VqEDTFk9ouYxYGiwDoL?usp=sharing*
- Drive/Datasets/Notebook & Artefactos *https://drive.google.com/drive/folders/1NkZ6kv_qt_HE2uL2GLREaLmqH1jvzBQY?usp=sharing*
- Contacto: *srdelosdatos@gmail.com* ‚Äî *www.linkedin.com/in/srdelosdatos* ‚Äî 
